# DocQA ğŸ¤–
![image](https://github.com/afaqueumer/DocQA/assets/98417654/971c5d0f-3863-4d2b-858b-6f97e85e0f9d)

DocQA ğŸ¤– is a web application built using Streamlit ğŸ”¥ and the LangChain ğŸ¦œğŸ”— framework, allowing users to leverage the power of LLMs for Generative Question Answering. ğŸŒŸ

Read More Here ğŸ‘‰
https://ai.plainenglish.io/ï¸-langchain-streamlit-llama-bringing-conversational-ai-to-your-local-machine-a1736252b172

## Installation
To run the LangChain web application locally, follow these steps:

Clone this repository ğŸ”—
```
git clone https://github.com/afaqueumer/DocQA.git
```
Create Virtual Environment and Install the required dependencies âš™ï¸
```
Run â¡ï¸ setup_env.bat 
```
Launch Streamlit App ğŸš€
```
Run â¡ï¸ run_app.bat
```
## Usage
Once you have the Streamlit  web application up and running, you can perform the following steps:

1. Upload the Text File.
2. Once the Text File is loaded as the Vector Store Database it will show a success alert "Document is Loaded".
3. Insert the question in "Ask" textbox and submit your question for LLM to generate the answer.

## Contributing
Contributions to this app are welcome! If you have any ideas, suggestions, or bug fixes, please feel free to open an issue or submit a pull request. We appreciate your contributions.

## License
This project is licensed under the MIT License.

ğŸ‰ Thank you ğŸ¤— Happy question answering! ğŸŒŸ
